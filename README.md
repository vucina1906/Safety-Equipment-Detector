This project is a part of bigger project I did for my previous employeer. Beside other safety measures the rules were for every worker to wear safety vests and hard hats. We trained models on roboflow data (link https://universe.roboflow.com/roboflow-universe-projects/construction-site-safety/dataset/28), like I did in this example but also include images from our field that I can not share due to obvious reasons. Images were labeled using free software labelImg that we downloaded from github repo on link github.com/heartexlabs/labelimg. 

If you are planning to use it and train model on your custom data the most important part is to prepeare files and store them to be ready for YOLO algorithm training. In my case I was using YOLOv8 version, large model same as I did here.Than model weights are stored in best.pt file that you will get in google colab after almost 2 hours of training in my case. Best.pt file will be stored in google colab content folder than folder runs than folder detect than folder train. In train file you will also get other results in form of .png and .jpg files, F1_curve,P_curve etc.. in fodler weights you will find best.pt that you should download. 

Whole code is in script main.py Here is example how model did on random video mp4 samples. If you are going to connect the script to live video from your cameras you have to use cameras IP adresses ad change the code cv2.VideoCapture("rtsp://<camera_ip>:<port>/stream"). Also if you want to customize code you can change algorithm to detect safety masks for example and use it in production area where masks are priority or in hospital environments. 

I also added alarm in script that can trigger the  person that monitor workplace and if you do not have person monitoring these cameras on your site the script will store timestamps in .txt file so later you can analyse if some workers did not follow safety rules and measures. 